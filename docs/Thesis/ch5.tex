\chapter{Methodology} \label{methodology}

\section{Final Study} \label{final_study}
% TODO: Need to find all references to final_study and then remove this as a section, and change subsections to sections
In the final study, the Xbox Controller Keyboard was removed due to its irrelevance; see Section~\ref{future_gaming_keyboard} for more information on how gaming consoles' virtual keyboards could be improved by moving away from single-input text entry and instead implementing a word-gesture keyboard. In addition, the use of a stylus was removed as an interaction tool from all mid-air keyboards, allowing participants to interact barehanded with the mid-air keyboard inputs.

\subsection{Participants} \label{final_participants}
A sample size of 18 was used in the final study. The justification for this sample size comes from the formula to calculate the sample size for two independent group means using a pooled standard deviation \cite{ref_sample_size}:
\begin{equation}
N = \frac{2(z_{\frac{\alpha}{2}} + z_{1-\beta})^2}{(\frac{\mu_1 - \mu_2}{\sigma_{pooled}})^2}
\end{equation}
where $z_{\frac{\alpha}{2}}$ and $z_{1-\beta}$ were the z-scores for the $\alpha$ and $\beta$, respectively, $\mu_1$ and $\mu_2$ were the means of the two populations being compared and $\sigma_{pooled}$ was the pooled standard deviation of the two populations. A power of $1-\beta = 0.80$ and a significance level of $\alpha = 0.05$ were used when calculating the sample size. The derived sample size was the average sample size for all relevant variable comparisons based on the study objectives. Outliers requiring a sample size greater than 100 were removed. Furthermore, a sample size of 18 justifies a Replicated Latin Squares design for 6 input methods. The Latin Squares design was chosen for counterbalancing the experimental design and to reduce the effect of participation in one condition affecting performance of other conditions. Further details are explained in Section~\ref{final_experimental_design}.

There were 13 male and 5 female participants, ages ranging from 18 to 24 with a median age of 21. Participants' computer usage ranged from 1 to greater than 50 hours per week with a median usage between 31 to 50 hours per week. All but two of the participants described their right hand as being dominant with one participant describing their left hand and the other claiming to be ambidextrous. Correspondingly, all participants used their right hand during the experiment except for one participant who used their left hand and another who switched back and forth. All of the participants had previous experience with touch devices, whereas 83\% of participants had previous experience with gesture-controllers and only 56\% having previous experience with word-gesture keyboards. No participants had any impairment that affected their ability to enter text with computers. Refer to Table~\ref{final_participant_stats} for more specific details on each participant.

\begin{table}[h]
	\centering
	\caption[Final Study Details of Participants]{\centering Participant information including age, gender, handedness, computer usage, and previous experiences.}
	\label{final_participant_stats}
	\resizebox{\textwidth}{!}{\begin{tabular}{ c | c c c c c c c c c c}
			\hline
			Subject & Gender & Age & Computer Usage & Handedness & Hand Used & Touch-device & Gesture-controller & Word-gesturing & Impairment \\
			{} & {} & {} & per Week (hours) & {} & in Experiment & Experience & Experience & Experience & History \\
			\hline
			1  & female & 20 & 41 - 50 & right & right & yes & yes & no  & no \\
			2  & male 	& 24 & 31 - 40 & right & right & yes & yes & yes & no \\
			3  & male 	& 19 & 1 - 5   & both  & both  & yes & yes & no  & no \\
			4  & male 	& 23 & 41 - 50 & right & right & yes & yes & yes & no \\
			5  & male 	& 21 & 21 - 30 & right & both  & yes & yes & no  & no \\
			6  & female & 22 & 50+     & right & right & yes & yes & yes & no \\
			7  & male 	& 18 & 41 - 50 & right & right & yes & yes & yes & no \\
			8  & female & 21 & 11 - 20 & right & right & yes & no  & yes & no \\
			9  & male 	& 22 & 50+     & left  & left  & yes & yes & yes & no \\
			10 & male 	& 18 & 21 - 30 & right & right & yes & yes & yes & no \\
			11 & female & 21 & 50+     & right & right & yes & no  & no  & no \\
			12 & male 	& 22 & 11 - 20 & right & right & yes & yes & yes & no \\
			13 & male 	& 22 & 50+     & right & right & yes & yes & no  & no \\
			14 & female & 18 & 50+     & right & right & yes & yes & yes & no \\
			15 & male 	& 23 & 50+     & right & right & yes & yes & no  & no \\
			16 & male 	& 18 & 6 - 10  & right & right & yes & no  & yes & no \\
			17 & male 	& 19 & 11 - 20 & right & right & yes & yes & no  & no \\
			18 & male	& 18 & 31 - 40 & right & right & yes & yes & no  & no \\
			\hline
		\end{tabular}}
	\end{table}

\subsection{Input Devices and Interaction} \label{final_devices}
In order to focus the study on only word-gesture keyboards, the final study saw the removal of the Xbox Controller Keyboard. Again, all of the keyboards except for the Touch Screen Keyboard were simulated on the same 64-bit, Windows 7 work station as before. The Touch Screen Keyboard was simulated on the Ideum Multi-touch Table Platform tabletop, running 64-bit Windows 8. All receivers or controllers were connected through USB 2.0. The participants were again allowed  to recalibrate the active keyboard's interaction plane; however, a default interaction space was provided that was unlikely to need to be recalibrated. Participants were encouraged to use the default-calibrated interaction space. Again, the participants were allowed to reposition the gesture-controller and were told to use the keyboards in whatever way they felt they could perform best.

A major change to all of the mid-air keyboards was that the stylus was removed. The absence of the stylus was aimed to remove the barrier between the participant and the keyboard input. The goal was to make it feel more natural and more like a touch screen.

\subsubsection{Touch Screen Keyboard}
The Touch Screen Keyboard was used on a large tabletop touch screen. The participant then used their finger to interact with the virtual keyboard on the screen in the same way as typical touch devices. Touch was simulated when the participants finger touched the screen and release was simulated when the finger was lifted from the surface.

\subsubsection{Leap Motion Surface Keyboard}
Again, for the Leap Motion Surface Keyboard a Leap Motion Controller was used for tracking. Unlike the other Leap-based keyboards, the gesture controller was placed into a custom designed holder instead of on the desk in front of the participant. The holder was attached to an inclined surface with a printed keyboard fixed on top. Placement, this time, was insured to be similar between uses, and therefore the Leap Motion Surface Keyboard required only a single calibration for all participants. The participant then used a stylus, as before, that was tracked by the Leap Motion in order to detect interaction. A touch was simulated by pressing the tip of the stylus against the printed keyboard and a release was simulated when the tip of the stylus was again removed from the printed keyboard surface.

\subsubsection{Leap Motion Static-Air Keyboard}
The Leap Motion Static-Air Keyboard used a Leap Motion Controller which was placed on the desk in front of the participant. The participant then used the pointer finger of their dominant hand, which was tracked by the Leap Motion, to interact with a projected interaction plane. A touch was simulated by the insertion of their finger into the interaction plane and a release was simulated upon the removal of their finger.

\subsubsection{Leap Motion Pinch-Air Keyboard}
The Leap Motion Pinch-Air Keyboard also used a Leap Motion Controller that was positioned on the desk in front of the participant. The participant then used their bare hand, which was tracked at the center of their palm, to interact with the projected interaction plane. Touch was simulated by having the participant make a pinching gesture with their hand and a release was simulated when the participant released the pinch, opening their hand again.

\subsubsection{Leap Motion Bimodal-Air Keyboard}
The Leap Motion Bimodal-Air Keyboard used a Leap Motion Controller positioned on the desk in front of the participant as before. The participant then used the pointer finger of their dominant hand, which was tracked by the Leap Motion, to determine the location over the projected virtual keyboard. A touch was simulated by pressing the space bar key on a standard QWERTY keyboard and a touch release was simulated upon the release of the space bar.

\subsubsection{Leap Motion Predictive-Air Keyboard}
As the others, the Leap Motion Predictive-Air Keyboard saw a Leap Motion Controller placed on the desk in front of the participant. The participant then used the pointer finger of their dominant hand, which was tracked by the Leap Motion, to interact with a projected interaction plane. A touch was simulated by recognizing and predicting a forward gesture of the participant's finger toward the interaction plane and a release was simulated by recognizing a backward gesture away from the interaction plane.

\subsection{Task Design} \label{final_task_design}
As in the pilot, the conditions of the task were represented by the 6 different keyboard input devices. The 6 conditions used were the Leap Motion Static-Air, Leap Motion Pinch-Air, Leap Motion Surface, Leap Motion Predictive-Air, Leap Motion Bimodal-Air, and Touch Screen keyboards.

Task profiles were created for each of the 6 keyboard input devices. Each task profile consisted of 15 separate trials for a total of 90 trials per participant. The increase in trials from 10 words to 15 words for each device was due to the removal of the Xbox Controller Keyboard. The creation of the task profiles was handled by generating static, unchanging dictionaries for each keyboard, guaranteeing a total of 90 unique words across all participants. The 15 words selected for each dictionary were again generated by the same custom dissimilarity algorithm, producing the top 15 least dissimilar gesture-shapes across all words in the Oxford English Dictionary for words of length 3 through 6 characters.

For each trial, a word was chosen at random from the active keyboard's previously constructed dictionary and displayed on the screen. A blank text-area was positioned directly below the displayed word for the participants' transcribed text. Beneath both text areas, the keyboard input devices were virtually represented. The participants were then required to use the currently active keyboard input device to enter the displayed word using word-gesturing. During the word-gesturing process, participants were again shown real-time updates. The participants were required to use the active keyboard device's backspace key to remove errors; however, already correct transcribed characters were still protected from being deleted. Once a word was correctly entered, the participants were to release the simulated touch to move to the next word.

\subsection{Experimental Design} \label{final_experimental_design}
As justified in the pilot, a within-subjects design was used for the final study. To minimize carryover effects, the study was supplemented with a Replicated Latin Squares design for counterbalancing \cite{ref_replicated_latin_squares}. Table~\ref{final_latin_squares_rep} shows how the Replicated Latin Squares design was utilized for 6 different keyboard inputs with a sample size of 18.

\begin{table}[h] % b - for bottom; !t - for top
	\centering
	\caption[Replicated Latin Squares Example]{\centering The three replications requires for a Replicated Latin Squares design for 18 participants and 6 conditions.}
	\label{final_latin_squares_rep}
	\begin{tabular}{c | c c c c c c}
		\multicolumn{7}{c}{First Replication} \\
		\hline
		participants & \multicolumn{6}{c}{conditions} \\
		\hline
		1 & A & B & C & D & E & F \\
		2 & B & C & D & E & F & A \\
		3 & C & D & E & F & A & B \\
		4 & D & E & F & A & B & C \\
		5 & E & F & A & B & C & D \\
		6 & F & A & B & C & D & E \\
		\hline
	\end{tabular}
	
	\vspace*{5mm}
	
	\begin{tabular}{c | c c c c c c}
		\multicolumn{7}{c}{Second Replication} \\
		\hline
		participants & \multicolumn{6}{c}{conditions} \\
		\hline
		7 & F & A & B & C & D & E \\
		8 & A & B & C & D & E & F \\
		9 & B & C & D & E & F & A \\
		10 & C & D & E & F & A & B \\
		11 & D & E & F & A & B & C \\
		12 & E & F & A & B & C & D \\
		\hline
	\end{tabular}
	
	\vspace*{5mm}
	
	\begin{tabular}{c | c c c c c c}
		\multicolumn{7}{c}{Third Replication} \\
		\hline
		participants & \multicolumn{6}{c}{conditions} \\
		\hline
		13 & E & F & A & B & C & D \\
		14 & F & A & B & C & D & E \\
		15 & A & B & C & D & E & F \\
		16 & B & C & D & E & F & A \\
		17 & C & D & E & F & A & B \\
		18 & D & E & F & A & B & C \\
		\hline
	\end{tabular}
\end{table}

\subsection{Procedure} \label{final_procedure}
Each subject participated in a single study visit which took between 30 and 45 minutes to complete. For this study, almost no calibrations were performed. The full set of tasks and their expected durations are detailed in Table~\ref{final_schedule_of_assessments}, the final study schedule of assessments. The participants followed the same process for each of the 6 keyboard input devices' tasks.

First, the participants were given a brief explanation and demonstration of the active keyboard input. The explanation dialog contained the name of the active keyboard and how it was interacted with. The researcher then demonstrated how to enter the word ``test'' using the active keyboard. The participants were then given control and interacted with the keyboard to get a sense of how it worked.

Participants were then instructed to use the keyboard to perform practice words which were randomly selected from the Oxford English Dictionary with lengths between 3 and 6 characters long. The practice words were again filtered for offensive words and against the previously constructed experiment dictionaries. There was no limit placed on how many words could be performed while practicing. The participants were told to continue until they felt they were able to efficiently and comfortably type each word with minimal errors. The participants were told that the keyboards could be recalibrated if absolutely necessary but were encouraged to learn to use the default calibration. This change was brought about because in the pilot study, participants had a hard time finding calibrations that worked, sometimes taking upwards of 30 minutes with poor results.

Next, the participants performed the task itself. As detailed in Section~\ref{final_task_design}, the participants were instructed to enter a total of 15 words for the current keyboard input device. The words selected were pulled at random from the active keyboard's previously constructed dictionary until all 15 words in the dictionary were used.

After the task for the active keyboard was completed, the participants were asked to fill out a small survey section, seen in Figure~\ref{fig_survey}. The survey asked participants to use the Likert scale to rate each keyboard in terms of difficulty, discomfort and fatigue experienced when using the devices.

Finally, after all tasks were completed for each of the 6 input devices, the participants were asked to fill out an exit survey shown in Figure~\ref{fig_exit_survey}. The exit survey, as in the pilot, asked the participants for their age, gender, major, and handedness as well as several questions detailing any prior touch, gesture-controller, or word-gesturing experience or impairments that might relate to the study. Lastly, the participants were asked to rank each device on a numerical scale from best to worst.

\begin{table}[h] % b - for bottom; !t - for top
	\centering
	\caption[Final Study Schedule of Assessments]{\centering Schedule of Assessments for a single study visit (in minutes).}
	\label{final_schedule_of_assessments}
	\resizebox{\textwidth}{!}{\begin{tabular}{ l | c c c c c c c | c}
		\hline
		{} & Touch & Leap Motion & Leap Motion & Leap Motion & Leap Motion & Leap Motion & Exit & \textbf{total}  \\
		{} & Screen & Surface & Static-Air & Pinch-Air & Predictive-Air & Bimodal-Air & Survey & {}  \\
		\hline
		explain & .5 & .5 & .5 & .5 & .5 & .5 & 0 & \textbf{3} \\
		calibrate & 0 & 0 & .5 & 0 & .5 & .5 & 0 & \textbf{1.5} \\
		practice & 3 & 3 & 3 & 3 & 3 & 3 & 0 & \textbf{18} \\
		task & 1.5 & 1.5 & 1.5 & 1.5 & 1.5 & 1.5 & 0 & \textbf{9} \\
		survey & .5 & .5 & .5 & .5 & .5 & .5 & 3 & \textbf{6} \\
		\hline
		\textbf{total} & \textbf{5.5} & \textbf{5.5} & \textbf{6} & \textbf{5.5} & \textbf{6} & \textbf{6} & \textbf{3} & \textbf{37.5} \\
		\hline
	\end{tabular}}
\end{table}

\subsection{Dependent Measures} \label{final_dependent_measures}
Again, because each individual trial was designed as a single word rather than a phrase that included many words, most dependent measures were analyzed on the word-gesture level. It was possible to analyze these values at the phrase level if the combined trials were viewed as a single phrase. In addition, due to the lack of word-recognition in the design of the word-gesture keyboard, the forcing of participants to make corrections to transcribed words, and to help accommodate for device detection errors that were out of the participants' control, some of the dependent measures were modified. The modifications that were used directly effected the data processing for the transcribed word.

The first of the modifications was by using the shortest form of the transcribed word, Table~\ref{shortest_transcribed} shows how this worked. The shortest-transcribed modification helps to account for device detection errors as well as the fact that participants were forced to correct words. The drawback; however, can be seen in Example 4 of Table~\ref{shortest_transcribed}. The intention seemed to be the word ``fired'' instead of ``fire,'' but this information was lost with the shortest-transcribed modification.

\begin{table}[h] % b - for bottom; !t - for top
	\centering
	\caption[Shortest-transcribed Examples]{\centering Examples of the shortest-transcribed modification.}
	\label{shortest_transcribed}
	\resizebox{\textwidth}{!}{\begin{tabular}{ l | l l l }
		\hline
		{} & Presented text: & Input Stream: & Transcribed text: \\
		\hline
		Example 1 & quick & wquiclk${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$quick & wquiclk \\
		Example 2 & dot & fdot${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$di${\leftarrow}$ot & fdot \\
		Example 3 & burn & burnm${\leftarrow}$ & burn \\
		Example 4 & fire & fuired${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$ired${\leftarrow}$ & fuire \\
		\hline
	\end{tabular}}
\end{table}

The second modification was by including backspaces as part of the presented word when a participant made mistakes, since participants were required to correct errors. With the modification to the presented text, the transcribed string was now represented by the entire input stream. Table~\ref{backspace_presented} shows how this worked. The main motivation behind this modification was to mirror the participants' requirement to use backspaces until a word was correctly entered, especially for the correctness measure, Fr\'echet Distance.

\begin{table}[h] % b - for bottom; !t - for top
	\centering
	\caption[Backspace-transcribed Examples]{\centering Examples of the backspace-transcribed modification.}
	\label{backspace_presented}
	\resizebox{\textwidth}{!}{\begin{tabular}{ l | l l l l }
		\hline
		{} & Presented text: & Input Stream: &  Modified Presented text: & Transcribed text: \\
		\hline
		Example 1 & quick & wquiclk${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$quick & ${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$quick & wquiclk${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$quick \\
		Example 2 & dot & fdot${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$di${\leftarrow}$ot & ${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$d${\leftarrow}$ot & fdot${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$di${\leftarrow}$ot \\
		Example 3 & burn & burnm${\leftarrow}$ & burn${\leftarrow}$ & burnm${\leftarrow}$ \\
		Example 4 & fire & fuired${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$ired${\leftarrow}$ & f${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$ire${\leftarrow}$ & fuired${\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}{\leftarrow}$ired${\leftarrow}$ \\
		\hline
	\end{tabular}}
\end{table}

\subsubsection{Text-Entry Rate}
Again, text-entry rates were calculated using modified Words Per Minute, Formula~\ref{WPM}, where $|T-1|$ was replaced with $|T|$ and $S$ represents the amount of time, in seconds, that was taken to transcribe the word including the time that it took to produce the first character. The text-entry rate was calculated with and without the shortest-transcribed modification.

\subsubsection{Error Rates}
There were several techniques used to measure error rates and find the best representation of keyboard performance and account for the task design.

The first error rate, again, uses modified Minimum Word Distance, Formula~\ref{MWD_simple}, where $IW$ were words where the participant made any mistakes at all regardless of corrections, and $CW$ were words where the participant got the word correct on the first attempt. The shortest-transcribed modification, though, allows for the original Minimum Word Distance formula, Formula~\ref{MWD} from Vulture \cite{ref_vulture}, where $P$ and $T$ were the sets of words in the presented and transcribed strings, and $\overline{S_P}$ was the mean size of the optimal alignments calculated on a per-word level.

Next, due to the addition of the shortest-transcribed modification and because of the lack of word-recognition implementation of the word-gesture keyboards, the Minimum String Distance error rate was able to be used \cite{ref_error_rates}. Using the simplified keystroke taxonomy that was presented before, Minimum String Distance could be defined as the formula
\begin{equation} \label{pilot_ter}
	MSD\ error\ rate = \frac{INF}{C + INF} \times 100\%
\end{equation}
wher e$C$ represented the correct characters in the transcribed text and $INF$ were the incorrect, not fixed characters in the transcribed text.

As before, the simplified Keystrokes Per Character formula, Formula~\ref{KSPC_simple}, was used where $C$ represented the correct characters in the transcribed text, $INF$ was the incorrect, not fixed characters in the transcribed text, $F$ was used to show the keystrokes which were editing functions, namely backspace, and $IF$ was the incorrect but fixed characters in the input stream, but not editing keys. Additionally, Formula~\ref{KSPC} was used with the shortest-transcribed modification.

The final error rate, again, was the simplified Total Error Rate from the Formula~\ref{TER_simple} where, again, $C$ represented the correct characters in the transcribed text, $INF$ was the incorrect, not fixed characters in the transcribed text, $F$ was used to show the keystrokes which were editing functions, namely backspace, and $IF$ was the incorrect but fixed characters in the input stream, but not editing keys. With the edition of the shortest-transcribed modification, Formula~\ref{TER} was also utilized.

\subsubsection{Correctness}
As in the pilot study, correctness of a single word-gesture was determined by calculating the Fr\'echet Distance between the expected word-gesture path and the participant's generated word-gesture path. Figure~\ref{code_frechet} shows the recursive implementation of Fr\'echet Distance used in this study where $P$ and $Q$ were the two paths being walked, $CA$ was the matrix that contains all possible distance values for each comparison, and $i$ and $j$ were the indices that were being examined for that particular recursive phase. The Fr\'echet Distance was also calculated for both the shortest-transcribed and backspace-transcribed modifications.

\subsubsection{Distance Measures}
The two primary distance measures were the distance traveled to complete a word's gesture-shape, recorded in centimeters, and the average velocity of the participant's hand recorded in centimeters per second.

\subsubsection{Timing Measures}
As before in the pilot, the primary time measure taken was the duration required to complete a word's gesture-shape in seconds. Additionally, the participant's reaction time to errors, the duration it took for participants to first simulate a touch, and the time it took to correctly enter the first letter were recorded.

\subsubsection{Quantitative Measures}
Again, there were two quantitative measures recorded, the number of practice words completed for each input per participant, and the number of times a touch was simulated for each subject per input.

\subsubsection{Qualitative Measures}
The qualitative measures, in the final study, were gathered from the intermittent surveys and the final exit survey. In the intermittent surveys, the participants were asked to rate each keyboard that they used in terms of discomfort, difficulty, and fatigue using a Likert scale with 5 options. In the final exit survey, participants ranked the keyboards from 1, most preferred, to 6, the least preferred. Again, see Figure~\ref{fig_exit_survey} to see the exit survey.

\section{Challenges}
\subsection{Word Separation}
When it comes to mid-air text-entry, one of the greatest challenges was finding a suitable means of distinguishing between separate words while minimizing complexity. Prior attempts saw selection-based techniques mostly with single-input text-entry \cite{ref_selection_based_mid_air,ref_mid_air_text_large_displays}, whereas more recent approaches explored gesture-based techniques \cite{ref_airstroke,ref_graffiti_vs_unistroke,ref_continuous_recognition} using defined input areas or handwriting techniques \cite{ref_air_handwriting,ref_air_writing_continuous_recognition,ref_mid_air_text_entry_handwriting,ref_detecting_handwritten_characters}. The limitation to using selection-based techniques and using hand-gestures to interpret letters for text-entry is that they were slow, suffering low text-entry rates \cite{ref_selection_based_mid_air,ref_mid_air_text_large_displays}. The most advantageous addition to gesture-based text-entry has been the advent of shape writing \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}, now known as word-gesturing, which was applied for the first time to mid-air by Markussen et al. \cite{ref_vulture}.

Markussen et al. used pinching as a means of separating between words using a glove with reflective markers and a large projected display \cite{ref_vulture}. The pinching gesture was also confined to one specific hand-gesture. Though an effective first look at mid-air word-gesture keyboards, the pinching gesture used in Vulture lacks adaptability between users, adding complexity and limiting word separation. In addition, using a glove with reflective markers, obtaining the required tracking equipment, and using a large projector display are all very inconvenient for the typical user and not easily accessible. The experience needed to be confined down to something that could be used casually with a desktop or laptop computer, and be variable enough to be used by those who do not have the ability to form pinching gestures.

\subsection{Motor Space vs Display Space}
% CHANGE SENTENCE STRUCTURE AND REMOVE ``WE''
Another factor that contributed to the complexity of mid-air text-entry was the fact that we have to deal with the motor space and display space being decoupled when working in mid-air \cite{ref_vulture}. According to Markussen et al., having to mentally re-couple these spaces is difficult because of the principle of stimulus-response compatibility \cite{ref_stimulus_response_compatibility}. Vulture tried to reduce this problem by using a motor space that was parallel to the display space however still only reached 59\% the text-entry rate of touch-based inputs.

\subsection{Fatigue}
The last thing to consider when working with mid-air was how fatiguing these gestures could be to produce over long periods of time. Even in Vulture, the participant was required to stand in front of the display, holding their arms out to interact \cite{ref_vulture}. This sort of posture while performing gestures is known to cause fatigue, known as the ``Gorilla Arm Syndrom'' \cite{ref_gorilla_arm,ref_fatigue_limitation}, and should be minimized for text-entry.

\section{Solutions}
\subsection{Word Separation}
To attempt to solve the issues faced by complex word separation, we will use the Leap Motion Controller to explore different means of word separation. The Leap Motion Controller was beneficial in that it allows for bare-handed, mid-air gestural interactions with sub-millimeter precision \cite{ref_leap_device_evaluation_1,ref_leap_device_evaluation_2}. It also can be easily obtained by ordinary users and runs on typical desktop computers.

The Leap Motion especially allows us to explore means of word separation in the 3rd-Dimension, however, this was discouraged in favor of pinching in Vulture \cite{ref_vulture}. Though discouraged, no empirical evidence was provided, prompting this study to explore the 3rd-Dimension to discover it's full range of problems and to seek possible solutions. The 3rd-Dimension will be utilized by implementing various approaches that also consider the $z$-direction of hand-movement.

A final alternative was to use a bimodal approach to mid-air interaction using a secondary input that replaces the pinching gesture, removing the requirement for producing a gesture or using the 3rd-Dimension. The aim was to vastly reduce the complexity of word separation in mid-air.

\subsection{Motor Space vs Display Space}
To address the issue of decoupling, the 3rd-Dimension will be utilized by implementing a default approach with a static plane in mid-air which was expected to heavily show the effects of decoupling. To study the real limitations and issues that decoupling has, the static interaction plane was be projected onto a surface with a printed keyboard beneath it. Additionally, in an attempt to minimize decoupling between the motor space and display space, an implementation was used that tried to predict when users were attempting to touch the mid-air interaction plane.

Additionally, as Vulture did with pinching, the bimodal approach aims to minimize the effects of decoupling by reducing the overall complexity of the interaction between the motor space and the displayed screen and removing the need to actively make specific hand-gestures. The bimodal approach aims to increase the simplicity of simulating touching.

\subsection{Fatigue} \label{gorilla_arm_syndrome}
This study introduced calibration of a custom interaction space, similar to that used in Personal Space \cite{ref_alvin_thesis}, to allow users the freedom to rest their arms during text-entry and combat the effects of ``Gorilla Arm Syndrom'' \cite{ref_darren_thesis,ref_gorilla_arm}. Though this area of research is highly beneficial to reducing fatigue for mid-air gestures, this feature was dropped as a requirement in favor of a study that was more focused on text-entry and word separation. The calibrated interaction space could also be further improved by implementing better methods of personally defined interaction spaces for resting arms \cite{ref_alvin_thesis,ref_darren_thesis}.