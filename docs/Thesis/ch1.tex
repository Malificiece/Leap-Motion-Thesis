\chapter{Introduction}

\section{Motivation}
This research was inspired by my Grandpa, an amputee who has trouble typing efficiently with standard computer keyboards. It is a long and arduous task to type long emails or messages when only one hand and typing each character individually. This led me to consider all of the other recent amputees from the long period of war in the Middle East and how many people have come home with their lives changed. Thinking about these individuals, I thought, "There must be a better way!". A way to make typing and other interactions with computers even simpler and more efficient, not as tedious as they were before. Working in the same space as Alvin Jude Hari Haran and Darren Guiness and seeing their work being done on accessibility with using mid-air gestures to control the mouse using the Leap Motion \cite{ref_leap_motion,ref_alvin_thesis,ref_darren_thesis}, it inspired me to try to put the same technology to use for working with mid-air keyboards. It was evident to me, with all the phones and tablets in the market today coming standard with word-gesture keyboards and efficient, single-handed text-entry, I was motivated to look for a way to apply these techniques to mid-air to replace conventional keyboard use.

At the beginning of this research, there were no other studies on mid-air, word-gesture keyboards. I sought to try many different techniques, focused mostly on word-gesture keyboards, to explore their usage in mid-air. Shortly after research began, Vulture was released \cite{ref_vulture}, an exciting study, and the first to apply word-gesture keyboards to mid-air text-entry; as a result, the focus of this research changed from seeing \textbf{\textit{if}} word-gesture keyboards could work for mid-air text-entry to exploring other alternatives for \textbf{\textit{how}} we interact with them.

\section{Background}
With the increase in gesture-controlled interfaces for touch screen and other modern devices, gesture-controls have started to see a transition for use in mid-air. Mid-air, gesture-controlled content has seen its emergence in large displays \cite{ref_pan_zoom_large_dispalys,ref_large_screen_pointing_gestures}, smart phones \cite{ref_multiscale_navigation}, augmented reality \cite{ref_augmented_reality}, and desktop computers \cite{ref_leap_painting,ref_darren_thesis,ref_alvin_thesis,ref_leap_pointing_device}. Mid-air pointing has been a common approach to many of these gesture-controlled interactions and is used to select and manipulate on-screen objects \cite{ref_large_display_pointing,ref_air_pointing,ref_ray_pointing_large_displays,ref_shadow_reaching,ref_freehand_pointing_large_displays,ref_large_screen_pointing_gestures}; however, means of reasonable mid-air text entry are fairly new. Past technologies allowed for mid-air text-entry, but those approaches have fallen short of any meaningful text entry rates \cite{ref_visual_touchpad}. More modern approaches of mid-air text-entry have seen improved results but still low, around 13 \cite{ref_selection_based_mid_air} to 18.9 \cite{ref_mid_air_text_large_displays} words per minute. These approaches were limited to selection of individual characters and also lacked the multi-tap feature of touch-based entry \cite{ref_selection_based_mid_air,ref_airstroke,ref_mid_air_text_large_displays}. Last year, the largest improvement was seen in mid-air text-entry when Markussen et al. \cite{ref_vulture} transitioned word-gesture keyboards for mid-air use with the development of Vulture, reaching a text-entry rate of 20.6 words per minute for their initial study. They achieved an even higher text-entry rate of 28.1 Words Per Minute in a second study with training of single, short phrases, indicating that learning the new techniques will help bring mid-air text-entry closer to touch-based text-entry. Vulture reached 59\% of the text entry rate of touch-based inputs \cite{ref_vulture}.

The purpose of this study is to use the Leap Motion \cite{ref_leap_motion}, a new and emerging technology \cite{ref_leap_painting,ref_leap_device_evaluation_1,ref_leap_device_evaluation_2}, for interpreting mid-air gestural inputs for text entry \cite{ref_leap_tech}. The only previous attempt for text entry with the Leap Motion was in mid-air handwriting \cite{ref_air_handwriting}; however, even regular hand-writing is slow and confined around 15 words per minute \cite{ref_handprinting_alternatives}. Instead, this study aims to follow the path of Markussen et al. \cite{ref_vulture} and use the Leap Motion to extend word-gesture keyboards to mid-air text-entry. Word-gesture keyboards have garnered popularity with the advent of smart phones and tablets and have been proven to perform well on touch screens \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone}. This study intends to use the Leap Motion to find alternatives to mid-air, word-gesture keyboards and find a better approach than wearing a glove or detecting pinching \cite{ref_vulture,ref_airstroke} for the mid-air equivalent of tapping and releasing for delimiters of words. This study will explore the option of using the extra degrees of freedom available in mid-air (e.g., depth) which was decided against by Markussen et al. \cite{ref_vulture} to point out the problems of solutions of these techniques. This study will also use other techniques of simulating touch for the mid-air equivalent of tapping and releasing for delimiters of words. The idea is to achieve something that is as simple to using a touch-based devices as possible while still allowing for a multi-functional workspace.

The rationale behind this research is to improve mid-air text entry using techniques that will still allow for other gesture-controls when working with gesture-interfaces \cite{ref_large_display_pointing,ref_air_pointing,ref_ray_pointing_large_displays,ref_shadow_reaching,ref_freehand_pointing_large_displays}. Touchless gesture-controllers for mid-air text-entry will benefit augmented reality (e.g., Google Glass, Microsoft HoloLens) and virtual reality (e.g., Oculus Rift). Furthermore, they will greatly benefit the medical industry (e.g., operating rooms, those with disabilities, pathogen research), providing sanitary, sterile, and efficient means of text-entry in fragile environments.

\section{Challenges}

\subsection{Word Separation}
When it comes to mid-air text-entry, one of the greatest challenges is finding a suitable means of distinguishing between separate inputs while minimizing complexity. Prior attempts saw selection-based techniques mostly with single-input text-entry \cite{ref_selection_based_mid_air,ref_mid_air_text_large_displays}, whereas more recent approaches explored gesture-based techniques \cite{ref_airstroke,ref_graffiti_vs_unistroke,ref_continuous_recognition} using defined input areas or handwriting techniques \cite{ref_air_handwriting,ref_air_writing_continuous_recognition,ref_mid_air_text_entry_handwriting,ref_detecting_handwritten_characters}. The limitations with these are that selection-based techniques and using hand-gestures to interpret letters for text-entry are slow with limited text-entry speeds \cite{ref_selection_based_mid_air,ref_mid_air_text_large_displays}. The most advantageous addition to gesture-based text-entry has been the advent of shape writing \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}, now known as word-gesturing, which was applied for the first time to mid-air by Markussen et al. \cite{ref_vulture}.

Markussen et al. used pinching as a means of separating between words using a glove with reflective markers and a large projected display \cite{ref_vulture}. The pinching gesture was also confined to one specific hand-gesture. Though an effective first look at mid-air word-gesture keyboards, the pinching gesture used in Vulture lacks adaptability between users, adding complexity and limiting word separation. In addition, using a glove with reflective markers, obtaining the required tracking equipment, and using a large projector display are all very inconvenient for the typical user and not easily accessible. The experience needs to be confined down to something that can be used casually with a desktop or laptop computer, and be variable enough to be used by those who do not have the ability to form pinching gestures.

\subsection{Motor Space vs Display Space}
Another factor contributing to the complexity of mid-air text-entry is the fact that we have to deal with the motor space and display space being decoupled when working in mid-air \cite{ref_vulture}. According to Markussen et al., having to mentally re-couple these spaces is difficult because of the principle of stimulus-response compatibility \cite{ref_stimulus_response_compatibility}. Vulture tried to reduce this problem by using a motor space that was parallel to the display space however still only reached 59\% the text-entry rate of touch-based inputs.

\subsection{Fatigue}
The Last thing to consider when working with mid-air is how fatiguing these gestures can be to produce over long periods of time. Even in Vulture, the participant is required to stand in front of the display, holding their arms out to interact \cite{ref_vulture}. This sort of posture while performing gestures is known to cause fatigue, known as the "Gorilla Arm Syndrom" \cite{ref_gorilla_arm,ref_fatigue_limitation}, and should be minimized for text-entry.

\section{Solutions}

\subsection{Word Separation}
To attempt to solve the issues faced by complex word separation, we will use the Leap Motion Controller to explore different means of word separation. The Leap Motion Controller is beneficial in that it allows for bare-handed, mid-air gestural interactions with sub-millimeter precision \cite{ref_leap_device_evaluation_1,ref_leap_device_evaluation_2}. It also can be easily obtained by ordinary users and runs on typical desktop computers.

The Leap Motion especially allows us to explore means of word separation in the 3rd-Dimension, however, this was discouraged in favor of pinching in Vulture \cite{ref_vulture}. Though discouraged, no empirical evidence was provided, prompting this study to explore the 3rd-Dimension to discover it's full range of problems and to seek possible solutions. The 3rd-Dimension will be utilized by implementing various approaches that also consider the $z$-direction of hand-movement.

A final alternative is to use a bimodal approach to mid-air interaction using a secondary input that replaces the pinching gesture, removing the requirement for producing a gesture or using the 3rd-Dimension. The aim is to vastly reduce the complexity of word separation in mid-air.

\subsection{Motor Space vs Display Space}
To address the issue of decoupling, the 3rd-Dimension will be utilized by implementing a default approach with a static plane in mid-air which is expected to heavily show the effects of decoupling. To study the real limitations and issues that this decoupling has, the static interaction plane will also be projected onto a surface with a printed keyboard beneath it. Also in an attempt to minimize decoupling between the motor space and display space while exploring 3D, an implementation will be used that tries to predict when users are gesturing to touch the mid-air interaction plane.

Additionally, as Vulture did with pinching, the bimodal approach aims to minimize the effects of decoupling by reducing the overall complexity of the interaction between the motor space and the displayed screen and removing the need to actively make specific hand-gestures. The bimodal approach aims to increase the simplicity of simulating touching.

\subsection{Fatigue} \label{gorilla_arm_syndrome}
This study introduced calibration of a custom interaction space, similar to that used in Personal Space \cite{ref_alvin_thesis}, to allow users the freedom to rest their arms during text-entry and combat the effects of "Gorilla Arm Syndrom" \cite{ref_darren_thesis,ref_gorilla_arm}. Though this area of research is highly beneficial to reducing fatigue for mid-air gestures, this feature was dropped as a requirement in favor of a study that was more focused on text-entry and word separation and can be further improved later by implementing better methods of personally defined interaction spaces for a resting arm \cite{ref_alvin_thesis,ref_darren_thesis}. 
