\chapter{Literature Review} \label{literature_review}
\hspace{\parindent}The literature review covers several important topics relevant to design and construct a mid-air, word-gesture keyboard. Background information of mid-air pointing is discussed in Section~\ref{mid_air_pointing} to understand methods for interacting with display areas from afar. The importance of barehanded interaction for gestural input is then examined in Section~\ref{barehanded_interaction}. Section~\ref{mid_air_text_entry} presents some of the most relevant past works on mid-air text-entry and how they have evolved over time. The influence of word-gesture keyboards for single-hand text-entry is analyzed in Section~\ref{word_gesture_keyboards}. Finally in Section~\ref{text_eval}, various techniques for text-entry evaluation are reviewed.

\section{Mid-air Pointing} \label{mid_air_pointing}
Finding alternatives to word separation (i.e., the technique used to delimit between different words) for mid-air text-entry heavily involves utilizing mid-air pointing to give character-level precision and determine the gesture-shapes being drawn. In the past, much of the research on mid-air pointing was done through casting rays onto an assortment of distant display screens \cite{ref_large_display_pointing,ref_air_pointing,ref_ray_pointing_large_displays,ref_shadow_reaching,ref_freehand_pointing_large_displays,ref_large_screen_pointing_gestures}. However, these methods vary vastly in their efficiency, precision, accuracy, and fatigue. Even something as simple as hand jitter was a limiting factor to these sub-par detection techniques for mid-air pointing. These issues have recently begun to be overcome thanks to products like the Leap Motion controller, which can deliver tracking precision on the sub-millimeter level and implements techniques to detect and stabilize for hand jitter \cite{ref_leap_device_evaluation_1,ref_leap_device_evaluation_2} Another major factor that had heavily affected these ray-casting techniques was their dependence on the distance from the display screen \cite{ref_mid_air_text_large_displays}. Markussen et al. \citeyear{ref_selection_based_mid_air} chose to minimize the distance dependence by projecting movement orthogonally onto the display to maintain a constant control-display ratio at the cost of the user's reach. A second option, the option used in this thesis, was to instead project an interaction plane in front of the user within their reach that was independent from the display space \cite{ref_alvin_thesis,ref_darren_thesis,ref_leap_pointing_device}. As stated by the principle of stimulus-response compatibility \cite{ref_stimulus_response_compatibility}, the major issue in decoupling (or separating) the motor space and display space was that participants had to recouple (or combine) these two spaces mentally \cite{ref_vulture}. Using different techniques to calibrate the motor space has shown to partially aid in re-coupling these spaces and provide for efficient pointing throughput \cite{ref_alvin_thesis,ref_darren_thesis}.

\section{Barehanded Interaction} \label{barehanded_interaction}
Generally to track gestures, users are required to wear gloves or use reflective markers \cite{ref_vulture,ref_airstroke}. However, users should not be encumbered by wearing wires or external devices for interactions \cite{ref_natural_interactions}. This was known as the design principle: ``Come As You Are'' \cite{ref_come_as_you_are}. Adhering to the ``Come As You Are'' design principle leads to the barehanded interaction method, allowing the participant to be free of attached wires or devices. The barehanded approach for gestural interactions has been shown to be better for gestures than traditional input devices \cite{ref_barehanded_interaction}. The Leap Motion controller was used to track these gestures because it has been shown to be an acceptable tracking device for barehanded gestural interactions \cite{ref_alvin_thesis,ref_darren_thesis,ref_leap_device_evaluation_1,ref_leap_device_evaluation_2,ref_leap_pointing_device} and supports the ``Come As You Are'' design approach.

\section{Mid-air Text-entry} \label{mid_air_text_entry}
Since its inception, many techniques have been used for mid-air text-entry that all vary in error rates and text-entry rates. Mid-air text-entry has evolved along-side both the techniques for normal text-entry and the hardware available for tracking tools and hands.

\subsection{Selection-based}
Some of the earliest work on mid-air text entry focused on selection-based techniques \cite{ref_mid_air_text_large_displays,ref_selection_based_mid_air}. Such efforts were centered around using various layouts \cite{ref_mid_air_text_large_displays,ref_selection_based_mid_air,ref_SEATO_layout_1,ref_accelerometer_text_entry}, hovering \cite{ref_visual_touchpad}, multi-tap \cite{ref_selection_based_mid_air}, accelerometers \cite{ref_accelerometer_text_entry, ref_mid_air_text_large_displays}, bimodal entry \cite{ref_mid_air_text_large_displays}, or even selection-wheels \cite{ref_mid_air_text_large_displays}. The major limitation to these techniques was that all of them used single-input text-entry, which is inherently slow. One of the earliest implementations, Visual Touchpad, used web-cams to track hand motion \cite{ref_visual_touchpad}. However, it was limited by the hardware and processing of the time, requiring a 3-second period of hovering to select an individual key. More recent efforts have performed better for selection-based techniques reaching rates as high as 18.9 WPM \cite{ref_mid_air_text_large_displays}, the highest mid-air text-entry rate ever achieved before Vulture \cite{ref_vulture}. These studies were limited, some providing no character production on erroneous input \cite{ref_mid_air_text_large_displays} and others requiring participants to learn a whole new keyboard layout \cite{ref_mid_air_text_large_displays,ref_selection_based_mid_air,ref_SEATO_layout_1,ref_SEATO_layout_2,ref_accelerometer_text_entry}.

\subsection{Gesture-based}
More recent efforts, as technology improved and gestures became more easily detected, have focused on looking at gesture-based techniques for mid-air text-entry. One prominent example was AirStroke \cite{ref_airstroke}, a Graffiti-based alphabet for text-entry, which achieved text-entry rates as high as 11.0 WPM. Implemented by using an Xbox Kinect, it also showed that gestures could be recognized continuously on an interaction plane that was projected in front of the user \cite{ref_continuous_recognition} and could be used for recognizing gestures for text-entry \cite{ref_graffiti_vs_unistroke}. The idea of utilizing an interactive gesture-space in front of the user has been further supported by recent research using the Leap Motion controller \cite{ref_alvin_thesis,ref_darren_thesis}. Other alternative gesture-based techniques have attempted to use handwriting in mid-air \cite{ref_air_handwriting,ref_air_writing_continuous_recognition,ref_mid_air_text_entry_handwriting,ref_detecting_handwritten_characters}. However, even analog handwriting is known to be slow, limited to around 15 WPM \cite{ref_handprinting_alternatives}.

\subsection{Word-gesture Keyboards}
Markussen et al. \citeyear{ref_vulture} developed the first and only mid-air word-gesture keyboard, Vulture. The Vulture keyboard was able to achieve the highest text-entry rates seen for mid-air in two studies, reaching 20.6 WPM with repeated sessions and 28.1 WPM with training on single, short phrases \cite{ref_vulture}. Vulture used one of the few publicly available and better-known implementations of word-gesture keyboards that was developed for phones, the SHARK$^2$ \cite{ref_shape_writing,ref_shark_wgk}, proving that word-gesture keyboards, implemented with traditional methods, work well for mid-air text-entry. However, Vulture did have some limitations; participants were required to use a glove with reflective markers for tracking pinching-based gestures over an orthogonally projected display \cite{ref_selection_based_mid_air}. Requiring the user to wear a glove with reflective markers violates the ``Come As You Are'' design principle, explained in Section~\ref{barehanded_interaction}. Additionally, an orthogonally projected display requires the user to be forced to be directly in front of the display \cite{ref_selection_based_mid_air}, whereas users should have the freedom to calibrate and move their interaction space anywhere \cite{ref_natural_interactions}.

\section{Word-gesture Keyboards} \label{word_gesture_keyboards}
Word-gesture keyboards have seen their emergence along-side the growth of touch-based, hand-held devices, now being shipped as the standard keyboard on many smart phone devices. Originally, word-gesture keyboards were known as shape-writing keyboards because of the process of tracing a word's gesture-shape as opposed to conventional single-input or multi-tap text-entry \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}. Traditional word-gesture keyboard implementations typically see text-entry rates as high as 25 WPM after 35 minutes of practice for beginners and up to around 46 WPM for well-practiced phrases or expert-level experience \cite{ref_shape_writing,ref_theoretical_expert_speeds}. These text-entry rates are the current standard for traditional, touch-based, word-gesture keyboards. However, it should be noted that these rates can be further increased, as shown by KeyScretch \cite{ref_keyscretch}. KeyScretch is a gesture-based text-entry method for touch screens based on a menu-augmented, word-gesture keyboard and was able to achieve text-entry rates reaching 44-50 WPM, dependent on the language.

A traditional part of implementing word-gesture keyboards is to include shape-recognition algorithms in order to best determine what words the user was trying to create \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}. A word-recognition based approach has been proven to work for word-gesture keyboards (e.g., SHARK$^2$, Vulture) \cite{ref_shape_writing,ref_shark_wgk,ref_vulture}. Therefore, a traditional word-gesture implementation was outside the scope and goals of this thesis. Because it was known in advance what word-gestures a user was going to attempt to produce, it was believed a word-gesture keyboard could be pseudo-implemented without word-recognition. This omission is detailed in Section~\ref{lacking_word_recognition} To ensure that the results were accurate and to analyze the effectiveness of a pseudo-implementation of a word-gesture keyboard, both a pinching-based and touch-based implementations were also examined.

\section{Text-entry Evaluation} \label{text_eval}
\subsection{Text-entry Rates}
The most important measure for testing the various methods of word separation was by monitoring the text-entry rate. Achieving text-entry rates on par with or greater than those produced in Vulture will shed light on improved techniques for mid-air, text-entry interactions. Text-entry rate was measured in Words Per Minute \cite{ref_wpm_word_gesture_formula}. However, the time to produce the first character must be included when timing word gestures \cite{ref_wpm_word_gesture_timing}.

\subsection{Error Rates}
The Vulture keyboard uses Minimum Word Distance to primarily detect error rates in the phrases that were transcribed \cite{ref_vulture}. However, due to the pseudo-implementation of the word-gesture keyboard and the fact that characters and errors could be produced mid-gesture, some character-level error rates were also observed. These error rates were determined using the Keystrokes Per Character, Minimum String Distance, and Total Error Rate \cite{ref_error_rates} methods. The Keystrokes Per Character method was not without its flaws, as noted by Soukoreff and MacKenzie \citeyear{ref_error_rates}. However, because characters were produced during the gesturing process, this might give some insight on the production rate of erroneous characters when using the pseudo word-gesture keyboard implementation.

\subsection{Correctness}
Word-gesture keyboards heavily rely on shape-recognition algorithms in order to determine which words are recognized and produced. However, many studies on mid-air keyboards analyze error rates of the final transcribed text rather than evaluate the correctness between the user-generated gesture and the shape of the intended-word. The Fr\'echet Distance gives us the ability to do just that. The Fr\'echet Distance between two curves $P$ and $Q$, or in this case gesture-shapes, was best defined as the minimum length leash needed to walk a dog when the person walks along $P$ and the dog walks along $Q$ \cite{ref_frechet}. The lower the calculated distance was between the two paths, the closer the two paths produced were to each other, indicating the correctness of the generated paths.

\section{Summary}
The literature review has covered a variety of important past works that have influenced the direction of this thesis to apply different methods of word separation to mid-air, word-gesture keyboards. Mid-air pointing has played an important role in mid-air selection and manipulation of on-screen objects by casting rays onto a distant display screen. Barehanded interaction is the ideal interaction method to produce natural gestures and follows the ``Come As You Are'' design principle. Mid-air text-entry and it's evolution over time have shown how techniques from touch-based text-entry have been applied in mid-air. Table~\ref{lit_review_summary} shows how rates have changed for the various text-entry techniques. The innovative boom of word-gesture keyboards on touch-based devices has changed the way that users are able to enter-text with a single hand. Finally, various text-entry evaluation techniques were identified to help analyze the usefulness of the different word separation techniques presented in this thesis.

\begin{table}[h]
	\centering
	\caption[Summary of Results]{\centering Summary of text-entry rates and methods examined in the literature review.}
	\label{lit_review_summary}
	\resizebox{\textwidth}{!}{\begin{tabular}{ l l c l }
	    \hline
	    Type & Method & Text-entry Rate (WPM) & Reference \\
	    \hline
	    \multirow{3}{*}{Touch} & Handwriting & $\approx15.0$ & \cite{ref_handprinting_alternatives} \\
		{} & Word-gesture Keyboard & $\approx46.0$ & \cite{ref_theoretical_expert_speeds} \\
		{} & KeyScretch & $\approx50.0$ & \cite{ref_keyscretch} \\
		\hline
		\multirow{4}{*}{Mid-air} & AirStroke & 11.0 & \cite{ref_airstroke} \\
		{} & Projected QWERTY & 13.2 & \cite{ref_selection_based_mid_air} \\ 
		{} & Distant QWERTY & 18.9 & \cite{ref_mid_air_text_large_displays} \\
		{} & Vulture & 28.1 & \cite{ref_vulture} \\
		\hline
	\end{tabular}}
\end{table}