\chapter{Literature Review}

\section{Mid-Air Pointing}
Finding alternatives to word separation for mid-air text-entry heavily involves utilizing mid-air pointing to give character-level precision and determine the gesture-shapes being drawn. In the past, much of the research on mid-air pointing was done through casting rays onto an assortment of distant display screens \cite{ref_large_display_pointing,ref_air_pointing,ref_ray_pointing_large_displays,ref_shadow_reaching,ref_freehand_pointing_large_displays,ref_large_screen_pointing_gestures}, however the methods vary vastly in their efficiency, precision, accuracy, and fatigue. Even something as simple as hand jitter was a limiting factor to these sub-par detection techniques for mid-air pointing. These issues have recently began to be overcome thanks to products like the Leap Motion Controller which can deliver tracking precision on the sub-millimeter level and implements techniques to detect and stabilize for hand jitter \cite{ref_leap_device_evaluation_1,ref_leap_device_evaluation_2} Another major factor that has heavily affected these ray-casting techniques is their dependence on the distance from the display screen \cite{ref_mid_air_text_large_displays}. Markussen et al. chose to minimize the distance dependence by projecting movement orthogonally onto the display to maintain a constant control-display ration at the cost of the user's reach \cite{ref_selection_based_mid_air}. A second option, the option used in this study, is to instead project an interaction plane in front of the user within their reach that is independent from the display space \cite{ref_alvin_thesis,ref_darren_thesis,ref_leap_pointing_device}. The major issue in decoupling the motor space and display space is that participants have to recouple the two spaces mentally, addressing the principle of stimulus-response compatibility \cite{ref_vulture,ref_stimulus_response_compatibility}. Although it is difficult to recouple these spaces, promising results have shown that the effects can be minimized using different techniques to calibrate the motor space and provide for efficient pointing throughput \cite{ref_alvin_thesis,ref_darren_thesis}.

\section{Barehanded Interaction}
% TODO: SWAP THIS SECTION AROUND SO THAT WE HAVE A REASON FOR SAYING WHY WE SHOULD
% USE BAREHANDED INTERCATION BECAUSE WHO CARES THAT ITS BETTER
Unlike Vulture, which utilized a glove with reflective markers, this study decided to make interactions as natural as possible and use a barehanded approach for gestural interactions. Users should not be forced to wear a glove or reflective markers for interactions \cite{ref_natural_interactions}; this is known as the design principle: "Come As You Are" \cite{ref_come_as_you_are}. The barehanded approach for gestural interactions has been showed to be better for gestures than traditional input devices \cite{ref_barehanded_interaction} and has been used for natural and relaxed gestures for computer interaction \cite{ref_natural_relaxed_gestures}. More recently, the Leap Motion Controller has been shown to be an acceptable tracking device for barehanded gestural interactions \cite{ref_alvin_thesis,ref_darren_thesis,ref_leap_device_evaluation_1,ref_leap_device_evaluation_2,ref_leap_pointing_device}.

\section{Mid-Air Text-Entry}
% CLAIRFY THE "EFFECTIVENESS" STATEMENT
Since its inception, many techniques have been used for mid-air text-entry that all vary in effectiveness, namely error rate and text-entry rate. Mid-air text-entry has evolved along-side both the techniques for normal text-entry and the hardware available for tracking tools and hands.

\subsection{Selection-Based}
% NEED TO PUT REFERENCES AFTER EACH STATEMENT
% BE CLEARER ON THE LAST PART TO WHICH ONE IS WHICH
Some of the earliest work on mid-air text entry focused mainly on selection-based techniques. For selection-based text-entry, efforts were centered around making targeted movements, hovering, or other techniques representing selection in order to indicate that a character was being pressed. The major limitation to these techniques is that they use single-input text-entry and are slow. One of the earliest implementations, even similar to what was constructed in this experiment is Visual Touchpad \cite{ref_visual_touchpad}; however, it was extremely limited by the hardware and processing of the time, requiring a 3-second period of hovering to select an individual key. More recent efforts have recently performed better for selection-based techniques reaching rates as high as 18.9 WPM \cite{ref_mid_air_text_large_displays} and 13.2 WPM \cite{ref_selection_based_mid_air} by utilizing new selection-based methods for text-entry utilizing a QWERTY-based layout. These studies; however, were limited, the former providing no character production on erroneous input \cite{ref_mid_air_text_large_displays} and the latter using orthogonal projection of the hand's position onto the display \cite{ref_selection_based_mid_air}.

\subsection{Gesture-Based}
More recent efforts as technology has improved and gestures have become more easily analyzed and detected, have focused on looking at gesture-based techniques for mid-air text-entry. One of the prominent examples is AirStroke \cite{ref_airstroke} which utilized a Graffiti-based alphabet for text-entry and achieved text-entry rates as high as 11.0 WPM. It was also shown, implemented by using an Xbox Kinect, that gestures could be recognized continuously on an interaction plane that was projected in front of the user \cite{ref_continuous_recognition} and could be used for recognizing gestures for text-entry \cite{ref_graffiti_vs_unistroke}. The idea of utilizing an interactive gesture-space in front of the user has been further supported by recent research using the Leap Motion Controller \cite{ref_alvin_thesis,ref_darren_thesis}. Other alternatives have attempted to use hand-writing as a gesture-based technique in mid-air \cite{ref_air_handwriting,ref_air_writing_continuous_recognition,ref_mid_air_text_entry_handwriting,ref_detecting_handwritten_characters}; however, even surface-based hand-writing for text-entry is known to be slow, limited to around 15 WPM \cite{ref_handprinting_alternatives}.

\subsection{Word-Gesture Keyboards}
% FIGUR OUT WHAT NEEDED TO BE CHANGED HERE
At the beginning of this research there was no other work that had been published on word-gesture keyboards in mid-air, however, shortly after research began, Markussen et al. released Vulture, the first mid-air word-gesture keyboard \cite{ref_vulture}. The Vulture keyboard was able to achieve superior text-entry rates for mid-air in two studies, reaching 20.6 WPM and 28.1 WPM using repeated sessions and training on short phrases \cite{ref_vulture}. Vulture used one of the few publicly available and better-known implementations of work-gesture keyboards that was developed for phones, the SHARK$^2$ \cite{ref_shape_writing,ref_shark_wgk}, and used a glove with reflective markers for tracking pinching-based gestures on an orthogonally projected display \cite{ref_selection_based_mid_air}.

\section{Word-Gesture Keyboards}
Word-gesture keyboards have seen their emergence along-side the growth of touch-based, hand-held devices, now shipping default on many smart phones. Originally, word-gesture keyboards were known as shape-writing keyboards because of the process of tracing a word's gesture-shape as opposed to conventional single-input or multi-tap text-entry \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}. Word-gesture keyboards have garnered text-entry rates as high as 25 WPM after 35 minutes of practice for beginners and up to 46.5 WPM for well-practice phrases \cite{ref_shape_writing}.

A traditional part of implementing word-gesture keyboards is to include shape-recognition algorithms in order to best determine what words the user is trying to create \cite{ref_shape_writing,ref_the_word_gesture_keyboard,ref_shapewriter_iphone,ref_shark_wgk,ref_shorthand_writing}. One of the most thorough and available examples of this is SHARK$^2$ \cite{ref_shape_writing,ref_shark_wgk}, as was used in Vulture \cite{ref_vulture}.

Word-recognition has been proven to work for word-gesture keyboards, therefore it sits outside the goals of this study. Since it is known in advanced what words and characters that a user is going to be attempting to produce, it believed a word-gesture keyboard can be pseudo-implemented without word-recognition. To ensure that the results are accurate and to analyze the effectiveness of a pseudo-implementation of a word-gesture keyboard, both a pinching-based and touch-based implementation will also be examined.

\section{Text-Entry Evaluation}

\subsection{Deviating from the Standard Phrases}
To evaluate text-entry, typically predefined phrases were generated and used \cite{ref_phrase_sets}; however, due to the pseudo word-gesture keyboard implementation and the large number of conditions used, it was chosen to deviate from these predefined phrase sets. The goal was to create new word dictionaries, avoiding whole phrases to prevent confusing language, and use a custom algorithm to measure the similarity of different gesture-shapes. This deviation was motivated by trying to create as similar of an experience as possible for each keyboard to ensure that there were no skewed results because of the limited number of trials in combination with an abundance of different conditions. Section~\ref{dictionary_creation} goes into full details about how this was implemented.

\subsection{Text-Entry Rates}
The most important measure for testing the various methods of word separation is by monitoring the text-entry rate. Achieving text-entry rates on par with or greater than those produced in Vulture will shed light on improved techniques for mid-air, text-entry interactions. Text-entry rate is measured in Words Per Minute \cite{ref_wpm_word_gesture_formula}; however, including the time to produce the first character must be included when timing word gestures \cite{ref_wpm_word_gesture_timing}. More details on this measure are given in Chapter~\ref{methodology}.

\subsection{Error Rates}
The Vulture keyboard uses Minimum Word Distance to primarily detect error rates in the phrases that are transcribed \cite{ref_vulture}. However, due to the pseudo-implementation of the word-gesture keyboard and the fact that characters and errors can be produced mid-gesture, some character level error rates were also observed. These error rates are the Keystrokes Per Character, Minimum String Distance, and Total Error Rate \cite{ref_error_rates}. Of the error rates introduced, the Keystrokes Per Character method is not without its flaws, as noted by Soukoreff and MacKenzie; however, because characters are produced during the gesturing process, this might give some insight on the production rate of erroneous characters when using the pseudo word-gesture keyboard implementation. Chapter~\ref{methodology} provides more details on how these were specifically used.

\subsection{Correctness}
Word-gesture keyboards heavily rely on shape-recognition algorithms in order to determine which words are recognized and produced; however, many of these studies analyze error rates of the final transcribed text, rather than evaluating the correctness between the user-generated gesture and the shape of the intended-word. The Fr\'echet Distance gives us the ability to do just that. The Fr\'echet Distance between two curves $P$ and $Q$, or in this case gesture-shapes, is best defined as the minimum length leash needed to walk a dog when the person walks along $P$ and the dog walks along $Q$ \cite{ref_frechet}. The lower the calculated distance is between the two paths, the closer the two paths produced are to each other, providing a way to rate the correctness of the generated paths. Section~\ref{pilot_correctness} gives the implementation of the Fr\'echet Distance algorithm in more detail.